{
 "metadata": {
  "name": "",
  "signature": "sha256:a6ca112163b997fdd52729241e5bbc1ab739a89ad64e2a960a4f8843d39cdd88"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Implementing the $k$-NN Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Apply the $k$-NN Algorithm\n",
      "* Using Cross Validation\n",
      "* Apply Scaling"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from __future__ import division\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from seaborn import plt\n",
      "from sklearn.datasets import load_iris\n",
      "\n",
      "load_iris?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The best data set to validate any classification algorithm's performance is the [Fisher Iris data set](http://en.wikipedia.org/wiki/Iris_flower_data_set), which is commonly included in any stats or machine learning package."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib.colors import ListedColormap\n",
      "from sklearn import neighbors, datasets, feature_selection\n",
      "from sklearn.cross_validation import train_test_split, cross_val_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Various variables we'll need to set intially.\n",
      "n_neighbors = range(1, 51, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load in the data\n",
      "iris = datasets.load_iris()\n",
      "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
      "iris_df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Parameter Search"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create the training (and test) set using scikit-learn's train_test_split function\n",
      "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=12)\n",
      "\n",
      "# Try this sequence again with the following random seed.\n",
      "# observe how it changes the scores of K quite dramatically\n",
      "# X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=8)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loop through each neighbors value from 1 to 51 and append\n",
      "# the scores\n",
      "scores = []\n",
      "for n in n_neighbors:\n",
      "    clf = neighbors.KNeighborsClassifier(n)\n",
      "    clf.fit(X_train, y_train)\n",
      "    scores.append(clf.score(X_test, y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(18,6))\n",
      "_ = plt.plot(n_neighbors, scores, linewidth=3.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Application of Cross Validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The work above shows that at 11 neighbors, we can get an ideal result that doesn't overfit the data. To verify this, we'll use cross validation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "clf = neighbors.KNeighborsClassifier(11, weights='uniform')\n",
      "scores = cross_val_score(clf, iris_df.values, iris.target, cv=5)\n",
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Below returns highest signifiance for features 2 and 3\n",
      "# (remember, Python uses index 0). \n",
      "n = np.arange(len(iris.feature_names))\n",
      "\n",
      "fig = plt.figure(figsize=(18,6))\n",
      "ax = fig.add_subplot(111)\n",
      "\n",
      "ax.bar(n, feature_selection.f_classif(iris.data, iris.target)[0])\n",
      "\n",
      "xtickNames = ax.set_xticklabels(iris.feature_names)\n",
      "ax.set_xticks(n)\n",
      "_ = plt.setp(xtickNames, rotation=45, fontsize=16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fit only the last two features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = neighbors.KNeighborsClassifier(11, weights='uniform')\n",
      "clf.fit(iris.data[:, 2:4], iris.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "h = .02  # step size in the mesh\n",
      "# Create color maps\n",
      "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
      "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the decision boundary. For that, we will assign a color to each\n",
      "# point in the mesh [x_min, m_max]x[y_min, y_max].\n",
      "x_min, y_min = iris_df.min()[['petal length (cm)', 'petal width (cm)']]\n",
      "x_max, y_max = iris_df.max()[['petal length (cm)', 'petal width (cm)']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
      "\n",
      "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Put the result into a color plot\n",
      "Z = Z.reshape(xx.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(18,6))\n",
      "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot also the training points\n",
      "plt.figure(figsize=(18,6))\n",
      "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
      "plt.scatter(iris_df['petal length (cm)'], iris_df['petal width (cm)'], c=iris.target, cmap=cmap_bold)\n",
      "plt.xlim(xx.min(), xx.max())\n",
      "plt.ylim(yy.min(), yy.max())\n",
      "plt.title(\"3-Class classification (k = {}, weights = '{}')\".format(clf.n_neighbors, clf.weights))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Scaling"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris_df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import scale"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_norm = pd.DataFrame(scale(iris.data), columns=iris.feature_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_norm.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_norm.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Lab"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Rerun the [parameter search](#Parameter-Search) with `random_state=8`. Do you get the same result for the optimal $k$\n",
      "2. Rerun the whole lab but using [scaled](#Scaling) data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Show and Tell"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}